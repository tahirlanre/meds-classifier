{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# packages to store and manipulate data\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# packages to train model\n",
    "import torch\n",
    "import transformers\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1 GPU(s) available.\n",
      "We will use the GPU: GeForce RTX 2080 Ti\n"
     ]
    }
   ],
   "source": [
    "# If there's a GPU available...\n",
    "if torch.cuda.is_available():    \n",
    "\n",
    "    # Tell PyTorch to use the GPU.    \n",
    "    device = torch.device(\"cuda\")\n",
    "\n",
    "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
    "\n",
    "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
    "\n",
    "# If not...\n",
    "else:\n",
    "    print('No GPU available, using the CPU instead.')\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load datasets into pandas dataframe\n",
    "df_training = pd.read_csv('../data/raw/task1_training.tsv', sep='\\t')\n",
    "df_validation = pd.read_csv('../data/raw/task1_validation.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training sentences: 55,419\n",
      "\n",
      "Number of validation sentences: 13,853\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Report the number of sentences in each datasets.\n",
    "print('Number of training sentences: {:,}\\n'.format(df_training.shape[0]))\n",
    "print('Number of validation sentences: {:,}\\n'.format(df_validation.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    55273\n",
       "1      146\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_training['class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading BERT tokenizer...\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer\n",
    "\n",
    "# Load the BERT tokenizer.\n",
    "print('Loading BERT tokenizer...')\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Apply tokenizer to datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tokenized = df_training['tweet'].apply(lambda x: tokenizer.encode(x, add_special_tokens=True))\n",
    "validate_tokenized = df_validation['tweet'].apply(lambda x: tokenizer.encode(x, add_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original:  26\n",
      "Token IDs: 36\n"
     ]
    }
   ],
   "source": [
    "# Print sentence 0, now as a list of IDs.\n",
    "print('Original: ', len(df_training.iloc[0]['tweet'].split()))\n",
    "print('Token IDs:', len(train_tokenized[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the max length of sentences from both train and validation sets\n",
    "train_max_length = max(len(x) for x in train_tokenized)\n",
    "validate_max_length = max(len(x) for x in validate_tokenized)\n",
    "MAX_LEN = max(train_max_length, validate_max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pad token so that they all have the same size\n",
    "train_padded = np.array([i + [0]*(MAX_LEN-len(i)) for i in train_tokenized.values])\n",
    "validate_padded = np.array([i + [0]*(MAX_LEN-len(i)) for i in validate_tokenized.values])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(55419, 81)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_padded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13853, 81)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validate_padded.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Masking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_attention_mask = np.where(train_padded != 0, 1, 0)\n",
    "validate_attention_mask = np.where(validate_padded != 0, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(55419, 81)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_attention_mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13853, 81)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validate_attention_mask.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert to PyTorch Data Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = df_training['class'].values\n",
    "validate_labels = df_validation['class'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13853"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(validate_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert all inputs and labels into torch tensors, the required datatype \n",
    "# for our model.\n",
    "train_inputs = torch.tensor(train_padded)\n",
    "validation_inputs = torch.tensor(validate_padded)\n",
    "\n",
    "train_labels = torch.tensor(train_labels)\n",
    "validation_labels = torch.tensor(validate_labels)\n",
    "\n",
    "train_masks = torch.tensor(train_attention_mask)\n",
    "validation_masks = torch.tensor(validate_attention_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "\n",
    "# The DataLoader needs to know our batch size for training, so we specify it \n",
    "# here.\n",
    "# For fine-tuning BERT on a specific task, the authors recommend a batch size of\n",
    "# 16 or 32.\n",
    "\n",
    "batch_size = 16\n",
    "\n",
    "# Create the DataLoader for our training set.\n",
    "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
    "train_sampler = RandomSampler(train_data)\n",
    "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
    "\n",
    "# Create the DataLoader for our validation set.\n",
    "validation_data = TensorDataset(validation_inputs, validation_masks, validation_labels)\n",
    "validation_sampler = SequentialSampler(validation_data)\n",
    "validation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Classification Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
    "\n",
    "# Load BertForSequenceClassification, the pretrained BERT model with a single \n",
    "# linear classification layer on top. \n",
    "model = BertForSequenceClassification.from_pretrained(\n",
    "    \"bert-base-uncased\", # Use the 12-layer BERT model, with an uncased vocab.\n",
    "    num_labels = 2, # The number of output labels--2 for binary classification.\n",
    "                    # You can increase this for multi-class tasks.   \n",
    "    output_attentions = False, # Whether the model returns attentions weights.\n",
    "    output_hidden_states = False, # Whether the model returns all hidden-states.\n",
    ")\n",
    "\n",
    "# Tell pytorch to run this model on the GPU.\n",
    "model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The BERT model has 201 different named parameters.\n",
      "\n",
      "==== Embedding Layer ====\n",
      "\n",
      "bert.embeddings.word_embeddings.weight                  (30522, 768)\n",
      "bert.embeddings.position_embeddings.weight                (512, 768)\n",
      "bert.embeddings.token_type_embeddings.weight                (2, 768)\n",
      "bert.embeddings.LayerNorm.weight                              (768,)\n",
      "bert.embeddings.LayerNorm.bias                                (768,)\n",
      "\n",
      "==== First Transformer ====\n",
      "\n",
      "bert.encoder.layer.0.attention.self.query.weight          (768, 768)\n",
      "bert.encoder.layer.0.attention.self.query.bias                (768,)\n",
      "bert.encoder.layer.0.attention.self.key.weight            (768, 768)\n",
      "bert.encoder.layer.0.attention.self.key.bias                  (768,)\n",
      "bert.encoder.layer.0.attention.self.value.weight          (768, 768)\n",
      "bert.encoder.layer.0.attention.self.value.bias                (768,)\n",
      "bert.encoder.layer.0.attention.output.dense.weight        (768, 768)\n",
      "bert.encoder.layer.0.attention.output.dense.bias              (768,)\n",
      "bert.encoder.layer.0.attention.output.LayerNorm.weight        (768,)\n",
      "bert.encoder.layer.0.attention.output.LayerNorm.bias          (768,)\n",
      "bert.encoder.layer.0.intermediate.dense.weight           (3072, 768)\n",
      "bert.encoder.layer.0.intermediate.dense.bias                 (3072,)\n",
      "bert.encoder.layer.0.output.dense.weight                 (768, 3072)\n",
      "bert.encoder.layer.0.output.dense.bias                        (768,)\n",
      "bert.encoder.layer.0.output.LayerNorm.weight                  (768,)\n",
      "bert.encoder.layer.0.output.LayerNorm.bias                    (768,)\n",
      "\n",
      "==== Output Layer ====\n",
      "\n",
      "bert.pooler.dense.weight                                  (768, 768)\n",
      "bert.pooler.dense.bias                                        (768,)\n",
      "classifier.weight                                           (2, 768)\n",
      "classifier.bias                                                 (2,)\n"
     ]
    }
   ],
   "source": [
    "# Get all of the model's parameters as a list of tuples.\n",
    "params = list(model.named_parameters())\n",
    "\n",
    "print('The BERT model has {:} different named parameters.\\n'.format(len(params)))\n",
    "\n",
    "print('==== Embedding Layer ====\\n')\n",
    "\n",
    "for p in params[0:5]:\n",
    "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
    "\n",
    "print('\\n==== First Transformer ====\\n')\n",
    "\n",
    "for p in params[5:21]:\n",
    "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
    "\n",
    "print('\\n==== Output Layer ====\\n')\n",
    "\n",
    "for p in params[-4:]:\n",
    "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: AdamW is a class from the huggingface library (as opposed to pytorch) \n",
    "# I believe the 'W' stands for 'Weight Decay fix\"\n",
    "optimizer = AdamW(model.parameters(),\n",
    "                  lr = 2e-5, # args.learning_rate - default is 5e-5, our notebook had 2e-5\n",
    "                  eps = 1e-8 # args.adam_epsilon  - default is 1e-8.\n",
    "                )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import get_linear_schedule_with_warmup\n",
    "\n",
    "# Number of training epochs (authors recommend between 2 and 4)\n",
    "epochs = 4\n",
    "\n",
    "# Total number of training steps is number of batches * number of epochs.\n",
    "total_steps = len(train_dataloader) * epochs\n",
    "\n",
    "# Create the learning rate scheduler.\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
    "                                            num_warmup_steps = 0, # Default value in run_glue.py\n",
    "                                            num_training_steps = total_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Function to calculate the accuracy of our predictions vs labels\n",
    "def flat_accuracy(preds, labels):\n",
    "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import datetime\n",
    "\n",
    "def format_time(elapsed):\n",
    "    '''\n",
    "    Takes a time in seconds and returns a string hh:mm:ss\n",
    "    '''\n",
    "    # Round to the nearest second.\n",
    "    elapsed_rounded = int(round((elapsed)))\n",
    "    \n",
    "    # Format as hh:mm:ss\n",
    "    return str(datetime.timedelta(seconds=elapsed_rounded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======== Epoch 1 / 4 ========\n",
      "Training...\n",
      "  Batch 1,000  of  3,464.    Elapsed: 0:01:47.\n",
      "  Batch 2,000  of  3,464.    Elapsed: 0:03:35.\n",
      "  Batch 3,000  of  3,464.    Elapsed: 0:05:23.\n",
      "\n",
      "  Average training loss: 0.01\n",
      "  Training epcoh took: 0:06:13\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 1.00\n",
      "  Validation took: 0:00:26\n",
      "\n",
      "======== Epoch 2 / 4 ========\n",
      "Training...\n",
      "  Batch 1,000  of  3,464.    Elapsed: 0:01:47.\n",
      "  Batch 2,000  of  3,464.    Elapsed: 0:03:33.\n",
      "  Batch 3,000  of  3,464.    Elapsed: 0:05:19.\n",
      "\n",
      "  Average training loss: 0.00\n",
      "  Training epcoh took: 0:06:08\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 1.00\n",
      "  Validation took: 0:00:26\n",
      "\n",
      "======== Epoch 3 / 4 ========\n",
      "Training...\n",
      "  Batch 1,000  of  3,464.    Elapsed: 0:01:46.\n",
      "  Batch 2,000  of  3,464.    Elapsed: 0:03:33.\n",
      "  Batch 3,000  of  3,464.    Elapsed: 0:05:20.\n",
      "\n",
      "  Average training loss: 0.00\n",
      "  Training epcoh took: 0:06:09\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 1.00\n",
      "  Validation took: 0:00:26\n",
      "\n",
      "======== Epoch 4 / 4 ========\n",
      "Training...\n",
      "  Batch 1,000  of  3,464.    Elapsed: 0:01:47.\n",
      "  Batch 2,000  of  3,464.    Elapsed: 0:03:33.\n",
      "  Batch 3,000  of  3,464.    Elapsed: 0:05:19.\n",
      "\n",
      "  Average training loss: 0.00\n",
      "  Training epcoh took: 0:06:09\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 1.00\n",
      "  Validation took: 0:00:26\n",
      "\n",
      "Training complete!\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "# This training code is based on the `run_glue.py` script here:\n",
    "# https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L128\n",
    "\n",
    "\n",
    "# Set the seed value all over the place to make this reproducible.\n",
    "seed_val = 42\n",
    "\n",
    "random.seed(seed_val)\n",
    "np.random.seed(seed_val)\n",
    "torch.manual_seed(seed_val)\n",
    "torch.cuda.manual_seed_all(seed_val)\n",
    "\n",
    "# Store the average loss after each epoch so we can plot them.\n",
    "loss_values = []\n",
    "\n",
    "# For each epoch...\n",
    "for epoch_i in range(0, epochs):\n",
    "    \n",
    "    # ========================================\n",
    "    #               Training\n",
    "    # ========================================\n",
    "    \n",
    "    # Perform one full pass over the training set.\n",
    "\n",
    "    print(\"\")\n",
    "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
    "    print('Training...')\n",
    "\n",
    "    # Measure how long the training epoch takes.\n",
    "    t0 = time.time()\n",
    "\n",
    "    # Reset the total loss for this epoch.\n",
    "    total_loss = 0\n",
    "\n",
    "    # Put the model into training mode. Don't be mislead--the call to \n",
    "    # `train` just changes the *mode*, it doesn't *perform* the training.\n",
    "    # `dropout` and `batchnorm` layers behave differently during training\n",
    "    # vs. test (source: https://stackoverflow.com/questions/51433378/what-does-model-train-do-in-pytorch)\n",
    "    model.train()\n",
    "\n",
    "    # For each batch of training data...\n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "\n",
    "        # Progress update every 1000 batches.\n",
    "        if step % 1000 == 0 and not step == 0:\n",
    "            # Calculate elapsed time in minutes.\n",
    "            elapsed = format_time(time.time() - t0)\n",
    "            \n",
    "            # Report progress.\n",
    "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
    "\n",
    "        # Unpack this training batch from our dataloader. \n",
    "        #\n",
    "        # As we unpack the batch, we'll also copy each tensor to the GPU using the \n",
    "        # `to` method.\n",
    "        #\n",
    "        # `batch` contains three pytorch tensors:\n",
    "        #   [0]: input ids \n",
    "        #   [1]: attention masks\n",
    "        #   [2]: labels \n",
    "        b_input_ids = batch[0].to(device)\n",
    "        b_input_mask = batch[1].to(device)\n",
    "        b_labels = batch[2].to(device)\n",
    "\n",
    "        # Always clear any previously calculated gradients before performing a\n",
    "        # backward pass. PyTorch doesn't do this automatically because \n",
    "        # accumulating the gradients is \"convenient while training RNNs\". \n",
    "        # (source: https://stackoverflow.com/questions/48001598/why-do-we-need-to-call-zero-grad-in-pytorch)\n",
    "        model.zero_grad()        \n",
    "\n",
    "        # Perform a forward pass (evaluate the model on this training batch).\n",
    "        # This will return the loss (rather than the model output) because we\n",
    "        # have provided the `labels`.\n",
    "        # The documentation for this `model` function is here: \n",
    "        # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
    "        outputs = model(b_input_ids, \n",
    "                    token_type_ids=None, \n",
    "                    attention_mask=b_input_mask, \n",
    "                    labels=b_labels)\n",
    "        \n",
    "        # The call to `model` always returns a tuple, so we need to pull the \n",
    "        # loss value out of the tuple.\n",
    "        loss = outputs[0]\n",
    "\n",
    "        # Accumulate the training loss over all of the batches so that we can\n",
    "        # calculate the average loss at the end. `loss` is a Tensor containing a\n",
    "        # single value; the `.item()` function just returns the Python value \n",
    "        # from the tensor.\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        # Perform a backward pass to calculate the gradients.\n",
    "        loss.backward()\n",
    "\n",
    "        # Clip the norm of the gradients to 1.0.\n",
    "        # This is to help prevent the \"exploding gradients\" problem.\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "\n",
    "        # Update parameters and take a step using the computed gradient.\n",
    "        # The optimizer dictates the \"update rule\"--how the parameters are\n",
    "        # modified based on their gradients, the learning rate, etc.\n",
    "        optimizer.step()\n",
    "\n",
    "        # Update the learning rate.\n",
    "        scheduler.step()\n",
    "\n",
    "    # Calculate the average loss over the training data.\n",
    "    avg_train_loss = total_loss / len(train_dataloader)            \n",
    "    \n",
    "    # Store the loss value for plotting the learning curve.\n",
    "    loss_values.append(avg_train_loss)\n",
    "\n",
    "    print(\"\")\n",
    "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
    "    print(\"  Training epcoh took: {:}\".format(format_time(time.time() - t0)))\n",
    "        \n",
    "    # ========================================\n",
    "    #               Validation\n",
    "    # ========================================\n",
    "    # After the completion of each training epoch, measure our performance on\n",
    "    # our validation set.\n",
    "\n",
    "    print(\"\")\n",
    "    print(\"Running Validation...\")\n",
    "\n",
    "    t0 = time.time()\n",
    "\n",
    "    # Put the model in evaluation mode--the dropout layers behave differently\n",
    "    # during evaluation.\n",
    "    model.eval()\n",
    "\n",
    "    # Tracking variables \n",
    "    eval_loss, eval_accuracy = 0, 0\n",
    "    nb_eval_steps, nb_eval_examples = 0, 0\n",
    "\n",
    "    # Evaluate data for one epoch\n",
    "    for batch in validation_dataloader:\n",
    "        \n",
    "        # Add batch to GPU\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "        \n",
    "        # Unpack the inputs from our dataloader\n",
    "        b_input_ids, b_input_mask, b_labels = batch\n",
    "        \n",
    "        # Telling the model not to compute or store gradients, saving memory and\n",
    "        # speeding up validation\n",
    "        with torch.no_grad():        \n",
    "\n",
    "            # Forward pass, calculate logit predictions.\n",
    "            # This will return the logits rather than the loss because we have\n",
    "            # not provided labels.\n",
    "            # token_type_ids is the same as the \"segment ids\", which \n",
    "            # differentiates sentence 1 and 2 in 2-sentence tasks.\n",
    "            # The documentation for this `model` function is here: \n",
    "            # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
    "            outputs = model(b_input_ids, \n",
    "                            token_type_ids=None, \n",
    "                            attention_mask=b_input_mask)\n",
    "        \n",
    "        # Get the \"logits\" output by the model. The \"logits\" are the output\n",
    "        # values prior to applying an activation function like the softmax.\n",
    "        logits = outputs[0]\n",
    "\n",
    "        # Move logits and labels to CPU\n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        label_ids = b_labels.to('cpu').numpy()\n",
    "        \n",
    "        # Calculate the accuracy for this batch of test sentences.\n",
    "        tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n",
    "        \n",
    "        # Accumulate the total accuracy.\n",
    "        eval_accuracy += tmp_eval_accuracy\n",
    "\n",
    "        # Track the number of batches\n",
    "        nb_eval_steps += 1\n",
    "\n",
    "    # Report the final accuracy for this validation run.\n",
    "    print(\"  Accuracy: {0:.2f}\".format(eval_accuracy/nb_eval_steps))\n",
    "    print(\"  Validation took: {:}\".format(format_time(time.time() - t0)))\n",
    "\n",
    "print(\"\")\n",
    "print(\"Training complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training loss over batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "# Use plot styling from seaborn.\n",
    "sns.set(style='darkgrid')\n",
    "\n",
    "# Increase the plot size and font size.\n",
    "sns.set(font_scale=1.5)\n",
    "plt.rcParams[\"figure.figsize\"] = (12,6)\n",
    "\n",
    "# Plot the learning curve.\n",
    "plt.plot(loss_values, 'b-o')\n",
    "\n",
    "# Label the plot.\n",
    "plt.title(\"Training loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('../models/vocab.txt',\n",
       " '../models/special_tokens_map.json',\n",
       " '../models/added_tokens.json')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save a trained model, configuration and tokenizer using `save_pretrained()`.\n",
    "# They can then be reloaded using `from_pretrained()`\n",
    "model.save_pretrained('../models/')\n",
    "tokenizer.save_pretrained('../models/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv('../data/raw/AnnotationDRUGSInTweets_EMNLPChallenge18_TrainingSetClean.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of test sentences: 9,622\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Report the number of tweets.\n",
    "print('Number of test sentences: {:,}\\n'.format(df_test.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize all of the texts and map tokens to their word IDs\n",
    "test_tokenized = df_test['text'].apply(lambda x: tokenizer.encode(x, add_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the max length of texts\n",
    "test_max_length = max(len(x) for x in test_tokenized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pad all texts to the same size\n",
    "test_padded = np.array([i + [0]*(test_max_length-len(i)) for i in test_tokenized.values])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a mask of 1s for each token followed by 0s for padding\n",
    "attention_mask = np.where(test_padded != 0, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = df_test.label.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to tensors.\n",
    "prediction_inputs = torch.tensor(test_padded)\n",
    "prediction_masks = torch.tensor(attention_mask)\n",
    "prediction_labels = torch.tensor(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the DataLoader.\n",
    "prediction_data = TensorDataset(prediction_inputs, prediction_masks, prediction_labels)\n",
    "prediction_sampler = SequentialSampler(prediction_data)\n",
    "prediction_dataloader = DataLoader(prediction_data, sampler=prediction_sampler, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting labels for 9,622 test sentences...\n",
      "    DONE.\n"
     ]
    }
   ],
   "source": [
    "# Prediction on test set\n",
    "\n",
    "print('Predicting labels for {:,} test sentences...'.format(len(prediction_inputs)))\n",
    "\n",
    "# Put model in evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Tracking variables \n",
    "predictions , true_labels = [], []\n",
    "\n",
    "# Predict \n",
    "for batch in prediction_dataloader:\n",
    "  # Add batch to GPU\n",
    "  batch = tuple(t.to(device) for t in batch)\n",
    "  \n",
    "  # Unpack the inputs from our dataloader\n",
    "  b_input_ids, b_input_mask, b_labels = batch\n",
    "  \n",
    "  # Telling the model not to compute or store gradients, saving memory and \n",
    "  # speeding up prediction\n",
    "  with torch.no_grad():\n",
    "      # Forward pass, calculate logit predictions\n",
    "      outputs = model(b_input_ids, token_type_ids=None, \n",
    "                      attention_mask=b_input_mask)\n",
    "\n",
    "  logits = outputs[0]\n",
    "\n",
    "  # Move logits and labels to CPU\n",
    "  logits = logits.detach().cpu().numpy()\n",
    "  label_ids = b_labels.to('cpu').numpy()\n",
    "  \n",
    "  # Store predictions and true labels\n",
    "  predictions.append(logits)\n",
    "  true_labels.append(label_ids)\n",
    "\n",
    "print('    DONE.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive samples: 4975 of 9622 (51.70%)\n"
     ]
    }
   ],
   "source": [
    "print('Positive samples: %d of %d (%.2f%%)' % (df_test.label.sum(), len(df_test.label), (df_test.label.sum() / len(df_test.label) * 100.0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating Matthews Corr. Coef. for each batch...\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import matthews_corrcoef\n",
    "\n",
    "matthews_set = []\n",
    "\n",
    "# Evaluate each test batch using Matthew's correlation coefficient\n",
    "print('Calculating Matthews Corr. Coef. for each batch...')\n",
    "\n",
    "# For each input batch...\n",
    "for i in range(len(true_labels)):\n",
    "  \n",
    "  # The predictions for this batch are a 2-column ndarray (one column for \"0\" \n",
    "  # and one column for \"1\"). Pick the label with the highest value and turn this\n",
    "  # in to a list of 0s and 1s.\n",
    "  pred_labels_i = np.argmax(predictions[i], axis=1).flatten()\n",
    "  \n",
    "  # Calculate and store the coef for this batch.  \n",
    "  matthews = matthews_corrcoef(true_labels[i], pred_labels_i)                \n",
    "  matthews_set.append(matthews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MCC: 0.462\n"
     ]
    }
   ],
   "source": [
    "# Combine the predictions for each batch into a single list of 0s and 1s.\n",
    "flat_predictions = [item for sublist in predictions for item in sublist]\n",
    "flat_predictions = np.argmax(flat_predictions, axis=1).flatten()\n",
    "\n",
    "# Combine the correct labels for each batch into a single list.\n",
    "flat_true_labels = [item for sublist in true_labels for item in sublist]\n",
    "\n",
    "# Calculate the MCC\n",
    "mcc = matthews_corrcoef(flat_true_labels, flat_predictions)\n",
    "\n",
    "print('MCC: %.3f' % mcc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score: 0.5888324873096447\n",
      "Accuracy: 0.68852629390979\n",
      "Precision: 0.9273984442523768\n",
      "Recall: 0.431356783919598\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score, precision_score, accuracy_score, recall_score\n",
    "\n",
    "# Calculate the evaluation metrics\n",
    "print(f'F1 score: {f1_score(flat_true_labels, flat_predictions)}')\n",
    "print(f'Accuracy: {accuracy_score(flat_true_labels, flat_predictions)}')\n",
    "print(f'Precision: {precision_score(flat_true_labels, flat_predictions)}')\n",
    "print(f'Recall: {recall_score(flat_true_labels, flat_predictions)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Evaluation metrics for the positive class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get positive labels\n",
    "np_true_labels = np.array(flat_true_labels)\n",
    "positive_labels_index = np.where(np_true_labels==1)\n",
    "positive_labels = np_true_labels[positive_labels_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Get prediction labels\n",
    "np_predictions = np.array(flat_predictions)\n",
    "positive_predictions = np_predictions[positive_labels_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score: 0.602724336469597\n"
     ]
    }
   ],
   "source": [
    "# Calculate the F1 score for positive class\n",
    "print(f'F1 score: {f1_score(positive_predictions, positive_labels)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
